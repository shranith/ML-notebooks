{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text-classification-20ng.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shranith/ML-notebooks/blob/master/text_classification_20ng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "feFbqZpP1soY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building a text classification model with TF Hub\n",
        "\n",
        "In this notebook, we'll walk you through building a model to predict the genres of a movie given its description. The emphasis here is not on accuracy, but instead how to use TF Hub layers in a text classification model.\n",
        "\n",
        "To start, import the necessary dependencies for this project."
      ]
    },
    {
      "metadata": {
        "id": "rOEllRxGQ_me",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca8c7261-5f7c-4152-b8fd-6a7cf64d06cf"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import json\n",
        "import pickle\n",
        "import urllib\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yLcRa_EjdehS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a86ec667-813b-46d2-a069-f20908f6fec5"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BkiJUAq0eGXl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aefa3fe0-2d23-4c77-8ed7-0b863167f213"
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!ls gdrive"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data\n",
            "'My Drive'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gw07kbavdnhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "f3a06d3c-b1fe-4ee0-d72c-5d6a9aa586bd"
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/gdrive/My Drive/20ng/20news-bydate-train.csv')\n",
        "print(data.head())\n",
        "\n",
        "descriptions = data['text']\n",
        "category = data['category']\n",
        "\n",
        "\n",
        "category[:10]\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   text_id                                               text  \\\n",
            "0     5701  From: nrmendel@unix.amherst.edu (Nathaniel Men...   \n",
            "1     1387  From: orly@phakt.usc.edu (Mr. Nitro Plastique)...   \n",
            "2     8953  From: hays@ssd.intel.com (Kirk Hays)\\n Subject...   \n",
            "3     2880  From: rnichols@cbnewsg.cb.att.com (robert.k.ni...   \n",
            "4     4348  From: steve-b@access.digex.com (Steve Brinich)...   \n",
            "\n",
            "                  category  \n",
            "0          rec.motorcycles  \n",
            "1    comp.sys.mac.hardware  \n",
            "2       talk.politics.guns  \n",
            "3  comp.os.ms-windows.misc  \n",
            "4                sci.crypt  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            rec.motorcycles\n",
              "1      comp.sys.mac.hardware\n",
              "2         talk.politics.guns\n",
              "3    comp.os.ms-windows.misc\n",
              "4                  sci.crypt\n",
              "5                alt.atheism\n",
              "6             comp.windows.x\n",
              "7                alt.atheism\n",
              "8                  sci.crypt\n",
              "9                  sci.crypt\n",
              "Name: category, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "xvwN2Jkx2CdU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The dataset\n",
        "\n",
        "We need a lot of text inputs to train our model. For this model we'll use [this awesome movies dataset](https://www.kaggle.com/rounakbanik/the-movies-dataset) from Kaggle. To simplify things I've made the `movies_metadata.csv` file available in a public Cloud Storage bucket so we can download it with `wget`. I've preprocessed the dataset already to limit the number of genres we'll use for our model, but first let's take a look at the original data so we can see what we're working with."
      ]
    },
    {
      "metadata": {
        "id": "WFKB0Bw62xW-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next we'll convert the dataset to a Pandas dataframe and print the first 5 rows. For this model we're only using 2 of these columns: `genres` and `overview`."
      ]
    },
    {
      "metadata": {
        "id": "MBLcNSE_7Icv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparing the data for our model\n",
        "\n",
        "I've done some preprocessing to limit the dataset to the top 9 genres, and I've saved the Pandas dataframes as public [Pickle](https://docs.python.org/3/library/pickle.html) files in GCS. Here we download those files. The resulting `descriptions` and `genres` variables are Pandas Series containing all descriptions and genres from our dataset respectively."
      ]
    },
    {
      "metadata": {
        "id": "JmOD3yjV_lS3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "12a25736-2b6f-44f5-8af3-47299bba81dc"
      },
      "cell_type": "code",
      "source": [
        "type(descriptions)\n",
        "descriptions[:10]\n",
        "\n",
        "print(type(category[1]))\n",
        "type(category)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "ZUypuN818T_D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Splitting our data\n",
        "When we train our model, we'll use 80% of the data for training and set aside 20% of the data to evaluate how our model performed."
      ]
    },
    {
      "metadata": {
        "id": "_nticMcj1alW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_size = int(len(descriptions) * .8)\n",
        "\n",
        "train_descriptions = descriptions[:train_size].astype('str')\n",
        "train_genres = category[:train_size]\n",
        "\n",
        "test_descriptions = descriptions[train_size:].astype('str')\n",
        "test_genres = category[train_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x5SLOv9JFbOy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        },
        "outputId": "1770dda9-aeae-451c-ded4-e757da1e3f76"
      },
      "cell_type": "code",
      "source": [
        "print(test_genres)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9016      comp.os.ms-windows.misc\n",
            "9017                  alt.atheism\n",
            "9018              rec.motorcycles\n",
            "9019       soc.religion.christian\n",
            "9020              rec.motorcycles\n",
            "9021      comp.os.ms-windows.misc\n",
            "9022             rec.sport.hockey\n",
            "9023                      sci.med\n",
            "9024      comp.os.ms-windows.misc\n",
            "9025                 misc.forsale\n",
            "9026      comp.os.ms-windows.misc\n",
            "9027              sci.electronics\n",
            "9028                    sci.space\n",
            "9029             rec.sport.hockey\n",
            "9030                      sci.med\n",
            "9031              rec.motorcycles\n",
            "9032     comp.sys.ibm.pc.hardware\n",
            "9033      comp.os.ms-windows.misc\n",
            "9034     comp.sys.ibm.pc.hardware\n",
            "9035      comp.os.ms-windows.misc\n",
            "9036           talk.politics.guns\n",
            "9037      comp.os.ms-windows.misc\n",
            "9038     comp.sys.ibm.pc.hardware\n",
            "9039              sci.electronics\n",
            "9040              sci.electronics\n",
            "9041                      sci.med\n",
            "9042       soc.religion.christian\n",
            "9043                    sci.space\n",
            "9044                    sci.space\n",
            "9045                  alt.atheism\n",
            "                   ...           \n",
            "11240       talk.politics.mideast\n",
            "11241          rec.sport.baseball\n",
            "11242                   sci.crypt\n",
            "11243          talk.politics.guns\n",
            "11244              comp.windows.x\n",
            "11245                   sci.crypt\n",
            "11246       talk.politics.mideast\n",
            "11247          talk.politics.guns\n",
            "11248                 alt.atheism\n",
            "11249          rec.sport.baseball\n",
            "11250          talk.politics.misc\n",
            "11251          talk.politics.guns\n",
            "11252          rec.sport.baseball\n",
            "11253               comp.graphics\n",
            "11254                   rec.autos\n",
            "11255       talk.politics.mideast\n",
            "11256             rec.motorcycles\n",
            "11257               comp.graphics\n",
            "11258              comp.windows.x\n",
            "11259          talk.politics.guns\n",
            "11260            rec.sport.hockey\n",
            "11261                   rec.autos\n",
            "11262                     sci.med\n",
            "11263              comp.windows.x\n",
            "11264     comp.os.ms-windows.misc\n",
            "11265    comp.sys.ibm.pc.hardware\n",
            "11266       talk.politics.mideast\n",
            "11267                   rec.autos\n",
            "11268          rec.sport.baseball\n",
            "11269            rec.sport.hockey\n",
            "Name: category, Length: 2254, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FmZ9iqK88nSD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Formatting our labels\n",
        "When we train our model we'll provide the labels (in this case genres) associated with each movie. We can't pass the genres in as strings directly, we'll transform them into multi-hot vectors. Since we have 9 genres, we'll have a 9 element vector for each movie with 0s and 1s indicating which genres are present in each description."
      ]
    },
    {
      "metadata": {
        "id": "bouv0R-D7J45",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5b20fa73-e55a-4027-9998-b2ff335c4cd6"
      },
      "cell_type": "code",
      "source": [
        "# print(train_genres)\n",
        "\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit_transform(train_genres)\n",
        "train_encoded = encoder.transform(train_genres)\n",
        "test_encoded = encoder.transform(test_genres)\n",
        "num_classes = len(encoder.classes_)\n",
        "\n",
        "# Print all possible genres and the labels for the first movie in our training dataset\n",
        "print(encoder.classes_)\n",
        "print(train_encoded[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism' 'comp.graphics' 'comp.os.ms-windows.misc'\n",
            " 'comp.sys.ibm.pc.hardware' 'comp.sys.mac.hardware' 'comp.windows.x'\n",
            " 'misc.forsale' 'rec.autos' 'rec.motorcycles' 'rec.sport.baseball'\n",
            " 'rec.sport.hockey' 'sci.crypt' 'sci.electronics' 'sci.med' 'sci.space'\n",
            " 'soc.religion.christian' 'talk.politics.guns' 'talk.politics.mideast'\n",
            " 'talk.politics.misc' 'talk.religion.misc']\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ir8ez0K_9sYA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create our TF Hub embedding layer\n",
        "[TF Hub]() provides a library of existing pre-trained model checkpoints for various kinds of models (images, text, and more) In this model we'll use the TF Hub `universal-sentence-encoder` module for our pre-trained word embeddings. We only need one line of code to instantiate module. When we train our model, it'll convert our array of movie description strings to embeddings. When we train our model, we'll use this as a feature column.\n"
      ]
    },
    {
      "metadata": {
        "id": "PWuNUXq7a-7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3dab8680-ba76-447a-f0f0-e4db414ec87b"
      },
      "cell_type": "code",
      "source": [
        "description_embeddings = hub.text_embedding_column(\"descriptions\", module_spec=\"https://tfhub.dev/google/universal-sentence-encoder/2\", trainable=False)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
            "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/2'.\n",
            "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/2'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9vscf4Fo-iI-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Instantiating our DNNEstimator Model\n",
        "The first parameter we pass to our DNNEstimator is called a head, and defines the type of labels our model should expect. Since we want our model to output multiple labels, we’ll use multi_label_head here. Then we'll convert our features and labels to numpy arrays and instantiate our Estimator. `batch_size` and `num_epochs` are hyperparameters - you should experiment with different values to see what works best on your dataset."
      ]
    },
    {
      "metadata": {
        "id": "c0Vsmu9O21je",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "multi_label_head = tf.contrib.estimator.multi_class_head(\n",
        "    num_classes,\n",
        "    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8mTpWD_Q8GKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "453635f7-36f0-4ff9-d414-6034e905c18d"
      },
      "cell_type": "code",
      "source": [
        "features = {\n",
        "  \"descriptions\": np.array(train_descriptions).astype(np.str)\n",
        "}\n",
        "labels = np.array(train_encoded).astype(np.int32)\n",
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(features, labels, shuffle=True, batch_size=32, num_epochs=25)\n",
        "estimator = tf.contrib.estimator.DNNEstimator(\n",
        "    head=multi_label_head,\n",
        "    hidden_units=[64,10],\n",
        "    feature_columns=[description_embeddings])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpyijh07th\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpyijh07th', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2028f8e048>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5ak1cZPZ_ZYM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training and serving our model \n",
        "To train our model, we simply call `train()` passing it the input function we defined above. Once our model is trained, we'll define an evaluation input function similar to the one above and call `evaluate()`. When this completes we'll get a few metrics we can use to evaluate our model's accuracy.\n"
      ]
    },
    {
      "metadata": {
        "id": "jmtvJ5o3Olcg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2669
        },
        "outputId": "8c227034-c7ad-4d8f-dcc9-98c073923651"
      },
      "cell_type": "code",
      "source": [
        "estimator.train(input_fn=train_input_fn)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpyijh07th/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.9876974, step = 0\n",
            "INFO:tensorflow:global_step/sec: 12.7507\n",
            "INFO:tensorflow:loss = 2.9261374, step = 100 (7.850 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.4862\n",
            "INFO:tensorflow:loss = 2.6610343, step = 200 (8.004 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.5786\n",
            "INFO:tensorflow:loss = 1.9961158, step = 300 (7.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.7406\n",
            "INFO:tensorflow:loss = 1.7117159, step = 400 (7.853 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.6635\n",
            "INFO:tensorflow:loss = 1.5663458, step = 500 (7.896 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.91\n",
            "INFO:tensorflow:loss = 1.2218494, step = 600 (7.742 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.9563\n",
            "INFO:tensorflow:loss = 1.0994418, step = 700 (7.718 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.8579\n",
            "INFO:tensorflow:loss = 1.2769351, step = 800 (7.778 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.9022\n",
            "INFO:tensorflow:loss = 1.0924256, step = 900 (7.751 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.7213\n",
            "INFO:tensorflow:loss = 1.0301719, step = 1000 (7.860 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.2285\n",
            "INFO:tensorflow:loss = 1.0978065, step = 1100 (8.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.954\n",
            "INFO:tensorflow:loss = 1.0610085, step = 1200 (7.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.1994\n",
            "INFO:tensorflow:loss = 1.1596098, step = 1300 (7.579 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.7543\n",
            "INFO:tensorflow:loss = 1.3313015, step = 1400 (7.841 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.0745\n",
            "INFO:tensorflow:loss = 0.90526354, step = 1500 (7.646 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.4588\n",
            "INFO:tensorflow:loss = 1.2541962, step = 1600 (7.434 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.8492\n",
            "INFO:tensorflow:loss = 0.7219368, step = 1700 (7.781 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.0818\n",
            "INFO:tensorflow:loss = 0.74527717, step = 1800 (7.645 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2925\n",
            "INFO:tensorflow:loss = 0.9186371, step = 1900 (7.519 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.9166\n",
            "INFO:tensorflow:loss = 0.89362824, step = 2000 (7.742 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2425\n",
            "INFO:tensorflow:loss = 0.9154414, step = 2100 (7.554 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2036\n",
            "INFO:tensorflow:loss = 0.6689615, step = 2200 (7.574 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.3194\n",
            "INFO:tensorflow:loss = 1.1097369, step = 2300 (7.508 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.4067\n",
            "INFO:tensorflow:loss = 1.0348665, step = 2400 (7.455 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.9981\n",
            "INFO:tensorflow:loss = 0.96683955, step = 2500 (7.694 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.9481\n",
            "INFO:tensorflow:loss = 0.63003325, step = 2600 (7.726 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.3995\n",
            "INFO:tensorflow:loss = 0.92337346, step = 2700 (7.462 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.8333\n",
            "INFO:tensorflow:loss = 1.113725, step = 2800 (7.789 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2041\n",
            "INFO:tensorflow:loss = 1.3055404, step = 2900 (7.576 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.9501\n",
            "INFO:tensorflow:loss = 0.7329327, step = 3000 (7.723 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.8869\n",
            "INFO:tensorflow:loss = 0.7602454, step = 3100 (7.761 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.419\n",
            "INFO:tensorflow:loss = 0.8080931, step = 3200 (7.450 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2939\n",
            "INFO:tensorflow:loss = 0.8422787, step = 3300 (7.519 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.1352\n",
            "INFO:tensorflow:loss = 1.0431638, step = 3400 (7.617 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.0213\n",
            "INFO:tensorflow:loss = 1.1823214, step = 3500 (7.679 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2905\n",
            "INFO:tensorflow:loss = 0.88968515, step = 3600 (7.521 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.8067\n",
            "INFO:tensorflow:loss = 0.8135146, step = 3700 (7.810 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2983\n",
            "INFO:tensorflow:loss = 0.90471745, step = 3800 (7.522 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.3007\n",
            "INFO:tensorflow:loss = 0.6755498, step = 3900 (7.519 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.069\n",
            "INFO:tensorflow:loss = 1.0160279, step = 4000 (7.648 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.5907\n",
            "INFO:tensorflow:loss = 1.030767, step = 4100 (7.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.0371\n",
            "INFO:tensorflow:loss = 0.53754294, step = 4200 (7.674 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2992\n",
            "INFO:tensorflow:loss = 0.69850373, step = 4300 (7.518 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.194\n",
            "INFO:tensorflow:loss = 0.766955, step = 4400 (7.576 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.1088\n",
            "INFO:tensorflow:loss = 0.8147305, step = 4500 (7.628 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.9246\n",
            "INFO:tensorflow:loss = 0.7546052, step = 4600 (7.742 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2641\n",
            "INFO:tensorflow:loss = 0.67807215, step = 4700 (7.539 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2352\n",
            "INFO:tensorflow:loss = 0.9489993, step = 4800 (7.556 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.9591\n",
            "INFO:tensorflow:loss = 0.95883524, step = 4900 (7.713 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.6602\n",
            "INFO:tensorflow:loss = 0.95355004, step = 5000 (7.898 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.4072\n",
            "INFO:tensorflow:loss = 0.7273004, step = 5100 (8.064 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2525\n",
            "INFO:tensorflow:loss = 0.9254265, step = 5200 (7.542 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.0292\n",
            "INFO:tensorflow:loss = 1.0922211, step = 5300 (7.675 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2527\n",
            "INFO:tensorflow:loss = 0.72072357, step = 5400 (7.548 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.3319\n",
            "INFO:tensorflow:loss = 0.8118932, step = 5500 (7.500 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.1348\n",
            "INFO:tensorflow:loss = 0.98122656, step = 5600 (7.612 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2753\n",
            "INFO:tensorflow:loss = 0.8460227, step = 5700 (7.536 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.3334\n",
            "INFO:tensorflow:loss = 0.9001529, step = 5800 (7.498 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.0812\n",
            "INFO:tensorflow:loss = 1.0232813, step = 5900 (7.649 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.203\n",
            "INFO:tensorflow:loss = 0.75834596, step = 6000 (7.571 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.0984\n",
            "INFO:tensorflow:loss = 0.7665602, step = 6100 (7.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.0259\n",
            "INFO:tensorflow:loss = 1.0501583, step = 6200 (7.678 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.4391\n",
            "INFO:tensorflow:loss = 0.78467906, step = 6300 (7.440 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.0418\n",
            "INFO:tensorflow:loss = 0.5901023, step = 6400 (7.668 sec)\n",
            "INFO:tensorflow:global_step/sec: 12.9554\n",
            "INFO:tensorflow:loss = 0.96001464, step = 6500 (7.719 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.7706\n",
            "INFO:tensorflow:loss = 0.70670736, step = 6600 (7.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.3656\n",
            "INFO:tensorflow:loss = 0.71373564, step = 6700 (7.481 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.0419\n",
            "INFO:tensorflow:loss = 1.083092, step = 6800 (7.666 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.3972\n",
            "INFO:tensorflow:loss = 0.77786225, step = 6900 (7.468 sec)\n",
            "INFO:tensorflow:global_step/sec: 13.2099\n",
            "INFO:tensorflow:loss = 0.9265443, step = 7000 (7.566 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 7044 into /tmp/tmpyijh07th/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.72136503.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.contrib.estimator.python.estimator.dnn.DNNEstimator at 0x7f202c3fae48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "dMgti0YmJO7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d305b541-020b-48aa-841d-188f2d8a40f9"
      },
      "cell_type": "code",
      "source": [
        "# Define our eval input_fn and run eval\n",
        "eval_input_fn = tf.estimator.inputs.numpy_input_fn({\"descriptions\": np.array(test_descriptions).astype(np.str)}, test_encoded.astype(np.int32), shuffle=False)\n",
        "estimator.evaluate(input_fn=eval_input_fn)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-10-31-06:09:43\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpyijh07th/model.ckpt-7044\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-10-31-06:09:57\n",
            "INFO:tensorflow:Saving dict for global step 7044: accuracy = 0.71472937, average_loss = 0.88901, global_step = 7044, loss = 0.88745\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7044: /tmp/tmpyijh07th/model.ckpt-7044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.71472937,\n",
              " 'average_loss': 0.88901,\n",
              " 'global_step': 7044,\n",
              " 'loss': 0.88745}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "mcPyCfmWABVO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generating predictions on new data\n",
        "Now for the most fun part! Let's generate predictions on movie descriptions our model hasn't seen before. We'll define an array of 3 new description strings (the comments indicate the correct genres) and create a `predict_input_fn`. Then we'll display the top 2 genres along with their confidence percentages for each of the 3 movies."
      ]
    },
    {
      "metadata": {
        "id": "ixlCKF6NEkTx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test our model on some raw description data\n",
        "raw_test = [\n",
        "    \"An examination of our dietary choices and the food we put in our bodies. Based on Jonathan Safran Foer's memoir.\", # Documentary\n",
        "    \"After escaping an attack by what he claims was a 70-foot shark, Jonas Taylor must confront his fears to save those trapped in a sunken submersible.\", # Action, Adventure\n",
        "    \"A teenager tries to survive the last week of her disastrous eighth-grade year before leaving to start high school.\", # Comedy\n",
        "]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XHpMIWFsE4OB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "predict_input_fn = tf.estimator.inputs.numpy_input_fn({\"descriptions\": np.array(raw_test).astype(np.str)}, shuffle=False)\n",
        "results = estimator.predict(predict_input_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iMVzrHpPDvoy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "41be2f28-5c9a-471c-ad58-323bca3a2310"
      },
      "cell_type": "code",
      "source": [
        "# Display predictions\n",
        "for movie_genres in results:\n",
        "  top_2 = movie_genres['probabilities'].argsort()[-2:][::-1]\n",
        "  for genre in top_2:\n",
        "    text_genre = encoder.classes_[genre]\n",
        "    print(text_genre + ': ' + str(round(movie_genres['probabilities'][genre] * 100, 2)) + '%')\n",
        "  print('')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpyijh07th/model.ckpt-7044\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "sci.med: 95.14%\n",
            "soc.religion.christian: 3.24%\n",
            "\n",
            "rec.sport.hockey: 40.49%\n",
            "sci.space: 23.56%\n",
            "\n",
            "misc.forsale: 30.8%\n",
            "rec.motorcycles: 28.38%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CfZTfK-e7MJr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}